{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages and Import Dataset\n",
    "\n",
    "In this notebook, we’ll be working with the **Wisconsin Diagnostic Breast Cancer (WDBC)** dataset again. As a reminder, this dataset contains several features derived from digitized images of breast tumor cells obtained via fine needle aspirates (FNAs).\n",
    "\n",
    "Each row in the dataset represents one tumor, with a set of measurements calculated from the cell nuclei present in the image. The dataset has the following columns:\n",
    "- **ID**: Unique identifier for each tumor sample.\n",
    "- **Diagnosis**: The classification label for the tumor (Malignant or Benign).\n",
    "- **Radius Mean, Texture Mean, Perimeter Mean, Area Mean**: Various statistical properties of the tumor.\n",
    "- **Compactness, Concavity, Symmetry**: Other characteristics calculated from the shape and structure of the tumor cells.\n",
    "\n",
    "The target column is **Diagnosis**, which we will try to predict based on the other features in the dataset.\n",
    "\n",
    "This dataset was obtained from the UCI Machine Learning Repository, a well-known resource for datasets in the machine learning community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.read_csv('dataset/wdbc.csv')\n",
    "cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data \n",
    "by renaming \"M\" to \"Malignant\" and \"B\" to \"Benign\" using the `.replace` method. The `.replace` method takes one argument: a dictionary that maps previous values to desired new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Malignant', 'Benign'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer[\"diagnosis\"] = cancer[\"diagnosis\"].replace({\n",
    "    \"M\" : \"Malignant\",\n",
    "    \"B\" : \"Benign\"\n",
    "})\n",
    "\n",
    "cancer[\"diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>Benign</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302  Malignant        17.99         10.38          122.80   \n",
       "1      842517  Malignant        20.57         17.77          132.90   \n",
       "2    84300903  Malignant        19.69         21.25          130.00   \n",
       "3    84348301  Malignant        11.42         20.38           77.58   \n",
       "4    84358402  Malignant        20.29         14.34          135.10   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424  Malignant        21.56         22.39          142.00   \n",
       "565    926682  Malignant        20.13         28.25          131.20   \n",
       "566    926954  Malignant        16.60         28.08          108.30   \n",
       "567    927241  Malignant        20.60         29.33          140.10   \n",
       "568     92751     Benign         7.76         24.54           47.92   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0       1001.0          0.11840           0.27760         0.30010   \n",
       "1       1326.0          0.08474           0.07864         0.08690   \n",
       "2       1203.0          0.10960           0.15990         0.19740   \n",
       "3        386.1          0.14250           0.28390         0.24140   \n",
       "4       1297.0          0.10030           0.13280         0.19800   \n",
       "..         ...              ...               ...             ...   \n",
       "564     1479.0          0.11100           0.11590         0.24390   \n",
       "565     1261.0          0.09780           0.10340         0.14400   \n",
       "566      858.1          0.08455           0.10230         0.09251   \n",
       "567     1265.0          0.11780           0.27700         0.35140   \n",
       "568      181.0          0.05263           0.04362         0.00000   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                0.14710  ...        25.380          17.33           184.60   \n",
       "1                0.07017  ...        24.990          23.41           158.80   \n",
       "2                0.12790  ...        23.570          25.53           152.50   \n",
       "3                0.10520  ...        14.910          26.50            98.87   \n",
       "4                0.10430  ...        22.540          16.67           152.20   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564              0.13890  ...        25.450          26.40           166.10   \n",
       "565              0.09791  ...        23.690          38.25           155.00   \n",
       "566              0.05302  ...        18.980          34.12           126.70   \n",
       "567              0.15200  ...        25.740          39.42           184.60   \n",
       "568              0.00000  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale data \n",
    "by standardizing our features in the dataset, to make sure theyre on the same scale. As we've seen, differences in scale can disproportionately affect machine learning models that rely on distance metrics (e.g., K-Nearest Neighbors). \n",
    "The `StandardScaler()` function in the sklearn.preprocessing module is a widely used tool for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>Benign</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0      842302  Malignant     1.097064     -2.073335        1.269934   \n",
       "1      842517  Malignant     1.829821     -0.353632        1.685955   \n",
       "2    84300903  Malignant     1.579888      0.456187        1.566503   \n",
       "3    84348301  Malignant    -0.768909      0.253732       -0.592687   \n",
       "4    84358402  Malignant     1.750297     -1.151816        1.776573   \n",
       "..        ...        ...          ...           ...             ...   \n",
       "564    926424  Malignant     2.110995      0.721473        2.060786   \n",
       "565    926682  Malignant     1.704854      2.085134        1.615931   \n",
       "566    926954  Malignant     0.702284      2.045574        0.672676   \n",
       "567    927241  Malignant     1.838341      2.336457        1.982524   \n",
       "568     92751     Benign    -1.808401      1.221792       -1.814389   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0     0.984375         1.568466          3.283515        2.652874   \n",
       "1     1.908708        -0.826962         -0.487072       -0.023846   \n",
       "2     1.558884         0.942210          1.052926        1.363478   \n",
       "3    -0.764464         3.283553          3.402909        1.915897   \n",
       "4     1.826229         0.280372          0.539340        1.371011   \n",
       "..         ...              ...               ...             ...   \n",
       "564   2.343856         1.041842          0.219060        1.947285   \n",
       "565   1.723842         0.102458         -0.017833        0.693043   \n",
       "566   0.577953        -0.840484         -0.038680        0.046588   \n",
       "567   1.735218         1.525767          3.272144        3.296944   \n",
       "568  -1.347789        -3.112085         -1.150752       -1.114873   \n",
       "\n",
       "     concave points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               2.532475  ...      1.886690      -1.359293         2.303601   \n",
       "1               0.548144  ...      1.805927      -0.369203         1.535126   \n",
       "2               2.037231  ...      1.511870      -0.023974         1.347475   \n",
       "3               1.451707  ...     -0.281464       0.133984        -0.249939   \n",
       "4               1.428493  ...      1.298575      -1.466770         1.338539   \n",
       "..                   ...  ...           ...            ...              ...   \n",
       "564             2.320965  ...      1.901185       0.117700         1.752563   \n",
       "565             1.263669  ...      1.536720       2.047399         1.421940   \n",
       "566             0.105777  ...      0.561361       1.374854         0.579001   \n",
       "567             2.658866  ...      1.961239       2.237926         2.303601   \n",
       "568            -1.261820  ...     -1.410893       0.764190        -1.432735   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2.001237          1.307686           2.616665         2.109526   \n",
       "1      1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2      1.456285          0.527407           1.082932         0.854974   \n",
       "3     -0.550021          3.394275           3.893397         1.989588   \n",
       "4      1.220724          0.220556          -0.313395         0.613179   \n",
       "..          ...               ...                ...              ...   \n",
       "564    2.015301          0.378365          -0.273318         0.664512   \n",
       "565    1.494959         -0.691230          -0.394820         0.236573   \n",
       "566    0.427906         -0.809587           0.350735         0.326767   \n",
       "567    1.653171          1.430427           3.904848         3.197605   \n",
       "568   -1.075813         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                2.296076        2.750622                 1.937015  \n",
       "1                1.087084       -0.243890                 0.281190  \n",
       "2                1.955000        1.152255                 0.201391  \n",
       "3                2.175786        6.046041                 4.935010  \n",
       "4                0.729259       -0.868353                -0.397100  \n",
       "..                    ...             ...                      ...  \n",
       "564              1.629151       -1.360158                -0.709091  \n",
       "565              0.733827       -0.531855                -0.973978  \n",
       "566              0.414069       -1.104549                -0.318409  \n",
       "567              2.289985        1.919083                 2.219635  \n",
       "568             -1.745063       -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the original 'cancer' dataframe to ensure we're not modifying the original data\n",
    "standardized_cancer = cancer.copy()\n",
    "\n",
    "# Specify the columns that we do NOT want to scale (ID and diagnosis columns)\n",
    "columns_to_exclude = ['id', 'diagnosis']\n",
    "\n",
    "# Select the columns that we want to scale by excluding the 'id' and 'diagnosis' columns\n",
    "# This will return a list of the numeric columns we need to scale\n",
    "columns_to_scale = standardized_cancer.columns.difference(columns_to_exclude)\n",
    "\n",
    "# Initialize the StandardScaler to standardize the selected numeric columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler to the selected columns. This transforms the data so that each feature\n",
    "# has a mean of 0 and a standard deviation of 1, which is essential to prevent larger\n",
    "# scale features from dominating the analysis, especially for distance-based algorithms like KNN.\n",
    "standardized_cancer[columns_to_scale] = scaler.fit_transform(cancer[columns_to_scale])\n",
    "\n",
    "# Output the standardized dataframe with the scaled numeric columns\n",
    "standardized_cancer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, the `scikit-learn package` helps both with building a classifier as well as evaluating its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Golden rule of machine learning**: you cannot use the test data to build the model! If you do, the model gets to “see” the test data in advance, making it look more accurate than it really is. \n",
    "\n",
    "How about simplifying it like this:\n",
    "\n",
    "*Imagine how dangerous it could be if your model incorrectly predicts a patient’s tumor is benign when it’s actually malignant. Overestimating the accuracy of your model could lead to serious mistakes like that.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, when splitting data for classification tasks, we divide it into a training set and a test set to evaluate the model's performance. The training set, which usually makes up 50% to 95% of the total data, is used to help the model learn patterns and relationships. The remaining 5% to 50% is set aside as the test set, which is used to assess how well the model can handle new, unseen data.\n",
    "\n",
    "Think of it like preparing a doctor for an exam where they need to decide whether a tumor is cancerous or not. The training set is like the doctor’s study material—cases they practice with to get familiar with the symptoms and patterns of cancerous tumors. But you wouldn’t want to give them all the cases upfront. You need to reserve some unseen cases for the real test, which is where the test set comes in. These are the new cases the doctor faces during the exam, and the goal is to see how well they can apply their learning to fresh examples. If they perform well on the test cases, it shows that they’ve truly understood the task and aren’t just memorizing the practice cases.\n",
    "\n",
    "In practice, a 75/25 or 80/20 split is common for classification tasks, meaning 75% of the data is used for training and 25% for testing. This balance ensures the model has enough data to learn effectively, while still reserving a significant portion to evaluate how well it performs on new, unseen data. This approach helps prevent overfitting, where the model performs well on the training data but struggles with real-world examples.\n",
    "\n",
    "For this example, we’ll use 75% of the data for training—so the model has enough information to learn patterns—and 25% for testing, to ensure we have a reliable measure of its performance on unseen cases.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train_test_split` function from scikit-learn simplifies data splitting. Key parameters to consider are:\n",
    "\n",
    "- **`shuffle=True`** (default): Shuffles the data before splitting to avoid any ordering effects.\n",
    "- **`stratify`**: Ensures the training and testing sets maintain the same class distribution as the original data. For example, if 63% of your data is benign and 37% malignant, using `stratify` ensures these proportions are preserved in both sets.\n",
    "\n",
    "For reproducibility, we will set a random seed using numpy's `random.seed` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is NumPy?\n",
    "\n",
    "\"But wait, what is that `np.random.seed()` thing?\". It comes from **NumPy**, a popular Python library that helps us work with numbers and do math really fast, especially when dealing with large amounts of data. It's great for things like handling lists of numbers, performing calculations, and generating random numbers.\n",
    "\n",
    "The `np.random.seed()` function is used to control the randomness in your code. Normally, when we generate random numbers, they change every time we run the code. By setting a \"seed\" with `np.random.seed()`, we make sure the random numbers stay the same each time we run it. This is useful when we want consistent results for testing or comparisons.\n",
    "NumPy arrays are fast and powerful, allowing us to do all sorts of math and number operations easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# split the data, train_size means 75% will be used for training, \n",
    "# remaining is for testing. shuffle to avoid patterns during collection. \n",
    "cancer_train, cancer_test = train_test_split(\n",
    "    standardized_cancer, train_size=0.75, shuffle=True, stratify=standardized_cancer[\"diagnosis\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info` method shows that the training set has 426 observations and the test set has 143, reflecting a 75%/25% split. To check diagnosis distribution, use `value_counts(normalize=True)` on `cancer_train`. This reveals about 63% benign and 37% malignant cases, confirming that the class proportions were maintained in the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 426 entries, 164 to 284\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       426 non-null    int64  \n",
      " 1   diagnosis                426 non-null    object \n",
      " 2   radius_mean              426 non-null    float64\n",
      " 3   texture_mean             426 non-null    float64\n",
      " 4   perimeter_mean           426 non-null    float64\n",
      " 5   area_mean                426 non-null    float64\n",
      " 6   smoothness_mean          426 non-null    float64\n",
      " 7   compactness_mean         426 non-null    float64\n",
      " 8   concavity_mean           426 non-null    float64\n",
      " 9   concave points_mean      426 non-null    float64\n",
      " 10  symmetry_mean            426 non-null    float64\n",
      " 11  fractal_dimension_mean   426 non-null    float64\n",
      " 12  radius_se                426 non-null    float64\n",
      " 13  texture_se               426 non-null    float64\n",
      " 14  perimeter_se             426 non-null    float64\n",
      " 15  area_se                  426 non-null    float64\n",
      " 16  smoothness_se            426 non-null    float64\n",
      " 17  compactness_se           426 non-null    float64\n",
      " 18  concavity_se             426 non-null    float64\n",
      " 19  concave points_se        426 non-null    float64\n",
      " 20  symmetry_se              426 non-null    float64\n",
      " 21  fractal_dimension_se     426 non-null    float64\n",
      " 22  radius_worst             426 non-null    float64\n",
      " 23  texture_worst            426 non-null    float64\n",
      " 24  perimeter_worst          426 non-null    float64\n",
      " 25  area_worst               426 non-null    float64\n",
      " 26  smoothness_worst         426 non-null    float64\n",
      " 27  compactness_worst        426 non-null    float64\n",
      " 28  concavity_worst          426 non-null    float64\n",
      " 29  concave points_worst     426 non-null    float64\n",
      " 30  symmetry_worst           426 non-null    float64\n",
      " 31  fractal_dimension_worst  426 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 109.8+ KB\n"
     ]
    }
   ],
   "source": [
    "cancer_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "Benign       0.626761\n",
       "Malignant    0.373239\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_train[\"diagnosis\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Notebook 1 (Classification 1):\n",
    "\n",
    "Fit the model on the breast cancer data. \n",
    "\n",
    "The `X` argument specifies the predictor variables (independent variables), while the `y` argument specifies the response variable (dependent variable).\n",
    "\n",
    "Here, \n",
    "- `X=cancer_train[[\"perimeter_mean\", \"concavity_mean\"]]` *to specify both Perimeter and Concavity means are to be used as the predictors.* \n",
    "- `y=cancer_train[\"diagnosis\"]` *to specify that diagnosis is the response variable (the one we want to predict)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with k = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define predictor variable (X) and response variable (Y)\n",
    "\n",
    "knn.fit(X=cancer_train[[\"perimeter_mean\", \"concavity_mean\"]], y=cancer_train[\"diagnosis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the K-nearest neighbors classifier, we can predict whether each case in the test set is cancerous or not. We then compare these predictions with the actual diagnoses. The `diagnosis` column shows the actual results, and the `predicted` column shows what our classifier predicted. We'll display only the `ID`, `diagnosis`, and `predicted` columns from the test set to assess the classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>901028</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>901041</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>8810703</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>91813702</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8510824</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>9010877</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>908469</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>892399</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>913512</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>897132</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  predicted\n",
       "357    901028     Benign     Benign\n",
       "361    901041     Benign     Benign\n",
       "212   8810703  Malignant  Malignant\n",
       "527  91813702     Benign     Benign\n",
       "21    8510824     Benign     Benign\n",
       "..        ...        ...        ...\n",
       "364   9010877     Benign     Benign\n",
       "434    908469     Benign     Benign\n",
       "299    892399     Benign     Benign\n",
       "488    913512     Benign     Benign\n",
       "332    897132     Benign     Benign\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicting on the test set first\n",
    "\n",
    "cancer_test[\"predicted\"] = knn.predict(cancer_test[[\"perimeter_mean\", \"concavity_mean\"]])\n",
    "cancer_test[[\"id\", \"diagnosis\", \"predicted\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't know how good our predictions are, we need to measure their accuracy. One way to assess how well our predictions match the actual labels in the test set is by calculating the **prediction accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine accuracy using the `score` method. Here, we pass the test data (predictors) and the actual labels (`cancer_test[\"diagnosis\"]`) to the method. This will evaluate how well the classifier's predictions match the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(\n",
    "    cancer_test[[\"perimeter_mean\", \"concavity_mean\"]],\n",
    "    cancer_test[\"diagnosis\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that the estimated accuracy of the classifier on the test data was 88%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a simple and widely used measure to summarize a classifier's performance. However, it only shows how often the model is correct overall and doesn't provide insight into the types of errors it makes. To get a clearer picture, you can use a **confusion matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Confusion Matrix?\n",
    "\n",
    "A confusion matrix breaks down the number of correct and incorrect predictions for each class, revealing the specific kinds of mistakes the classifier tends to make.\n",
    "\n",
    "**True Positive:** A malignant observation that was classified as malignant (top left).\n",
    "\n",
    "**False Positive:** A benign observation that was classified as malignant (bottom left).\n",
    "\n",
    "**True Negative:** A benign observation that was classified as benign (bottom right).\n",
    "\n",
    "**False Negative:** A malignant observation that was classified as benign (top right)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Predicted Malignant</th>\n",
    "    <th>Predicted Benign</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Actually Malignant</th>\n",
    "    <td>True Positive</td>\n",
    "    <td>False Negative</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Actually Benign</th>\n",
    "    <td>False Positive</td>\n",
    "    <td>True Negative</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the confusion matrix, we can use the `crosstab` function from pandas. Here, we provide the actual labels as the first argument and the predicted labels as the second argument. \n",
    "\n",
    "*Note* that crosstab orders columns alphabetically, so the positive label (Malignant) might not appear in the top left corner but will still be correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>Benign</th>\n",
       "      <th>Malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malignant</th>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  Benign  Malignant\n",
       "diagnosis                   \n",
       "Benign         88          2\n",
       "Malignant       9         44"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    cancer_test[\"diagnosis\"],\n",
    "    cancer_test[\"predicted\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix reveals the following:\n",
    "\n",
    "- 44 observations were correctly predicted as malignant.\n",
    "- 88 observations were correctly predicted as benign.\n",
    "- 9 observations were incorrectly classified as benign when they were actually malignant.\n",
    "- 2 observations were incorrectly classified as malignant when they were actually benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a perfect world, the classifier would have no false negatives or false positives and would achieve 100% accuracy. **In practice**, errors are inevitable. Therefore, consider which types of errors matter most for your application and use the confusion matrix to measure them. Key metrics derived from the confusion matrix include **precision** and **recall**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "\n",
    "Precision measures how many of the predicted positives are actually positive. High precision means that when the classifier predicts a positive, it's likely to be correct.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\textbf{False Positives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "Recall measures how many actual positive observations were correctly identified by the classifier. High recall means that if there is a positive instance in the test data, the classifier is likely to detect it.\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\textbf{False Negatives}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of manually coding the math, you can use the `precision_score` and `recall_score` functions from scikit-learn to compute precision and recall. \n",
    "\n",
    "Set the following parameters:\n",
    "- `y_true`: Actual labels from the diagnosis variable.\n",
    "- `y_pred`: Predicted labels from the predicted variable.\n",
    "- `pos_label`: Specify the label to be considered positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(\n",
    "    y_true=cancer_test[\"diagnosis\"], #actual label from test set\n",
    "    y_pred=cancer_test[\"predicted\"],  #actual label from prediction\n",
    "    pos_label=\"Malignant\" #we're interested in precision for the Malignant class\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision calculation by hand:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{True Positives (44)}}{\\text{True Positives (44)} + \\text{False Positives (2)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301886792452831"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(\n",
    "    y_true=cancer_test[\"diagnosis\"],\n",
    "    y_pred=cancer_test[\"predicted\"],\n",
    "    pos_label=\"Malignant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall calculation by hand:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{True Positives (44)}}{\\text{True Positives (44)} + \\text{False Negatives (9)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that the classifier achieved an estimated precision of 95.7% and a recall of 83.0% on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most predictive models in statistics and machine learning have parameters that influence their behavior. For instance, in K-nearest neighbors classification, $k$ is a parameter that determines how many neighbors contribute to the class vote. Different values of $k$ result in different classifiers and predictions.\n",
    "\n",
    "To find the best value for $k$ or tune any model parameter, we aim to maximize the classifier’s accuracy on unseen data. However, the test set should not be used during tuning. Instead, we split the training data into two subsets: one for **training the model** and the other for **evaluating its performance (validation)**. This approach helps select the optimal parameter value while keeping the test set untouched.\n",
    "\n",
    "so the data split would look like:\n",
    "\n",
    "![](./images/TVT.001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we’ll start by creating a single 75-25 train/validation split, training a K-nearest neighbors model, and evaluating its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785046728971962"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're re-using the train_test_split function here in order to split the training data into sub-training and validation sets.\n",
    "cancer_subtrain, cancer_validation = train_test_split(\n",
    "    cancer_train, train_size=0.75, stratify=cancer_train[\"diagnosis\"]\n",
    ")\n",
    "\n",
    "# fit the model on the sub-training data\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "X = cancer_subtrain[[\"perimeter_mean\", \"concavity_mean\"]]\n",
    "y = cancer_subtrain[\"diagnosis\"]\n",
    "knn.fit(X, y)\n",
    "\n",
    "# compute the score on validation data\n",
    "acc = knn.score(\n",
    "    cancer_validation[[\"perimeter_mean\", \"concavity_mean\"]],\n",
    "    cancer_validation[\"diagnosis\"]\n",
    ")\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we repeat the above code 4 more times, each time generating a new split with a different shuffle of the data, we get five different train/validation splits. \n",
    "\n",
    "![](./images/random_folds.001.png)\n",
    "\n",
    "Each split produces a new accuracy value based on the specific training and validation subsets used. This results in five different accuracy estimates over different runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of random splits, we can use **cross-validation** to ensure each observation is in the validation set only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "\n",
    "In cross-validation, we divide the training data into $C$ equal parts. Each part is used once as the validation set while the other $C-1$ parts form the training set. \n",
    "\n",
    "So as an example lets try and perform a 5 fold cross-validation.\n",
    "\n",
    "![](./images/CV.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform 5-fold cross-validation in Python using scikit-learn, use the `cross_validate` function. Here’s how:\n",
    "\n",
    "1. **Set `cv` to 5** for 5 folds.\n",
    "2. **Provide the training data predictors and labels** as `X` and `y`.\n",
    "\n",
    "The `cross_validate` function returns a dictionary. Convert it to a pandas DataFrame with `pd.DataFrame` for better visualization. It also automatically handles class stratification in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>0.930233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.870588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.952941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.917647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score\n",
       "0  0.007057    0.019892    0.930233\n",
       "1  0.004430    0.011828    0.894118\n",
       "2  0.003363    0.007995    0.870588\n",
       "3  0.002458    0.007374    0.952941\n",
       "4  0.003210    0.007496    0.917647"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "X = cancer_train[[\"perimeter_mean\", \"concavity_mean\"]]\n",
    "y = cancer_train[\"diagnosis\"]\n",
    "\n",
    "returned_dictionary = cross_validate(\n",
    "    estimator=knn,\n",
    "    cv=5,    # setting up the cross validation number\n",
    "    X=X,\n",
    "    y=y\n",
    ")\n",
    "\n",
    "cv_5_df = pd.DataFrame(returned_dictionary)    # Converting it to pandas DataFrame\n",
    "\n",
    "cv_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.913105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sem</th>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.014264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fit_time  score_time  test_score\n",
       "mean  0.004104    0.010917    0.913105\n",
       "sem   0.000803    0.002389    0.014264"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute mean and standard error of the mean (SEM) for each column\n",
    "cv_5_metrics = cv_5_df.agg([\"mean\", \"sem\"])\n",
    "\n",
    "cv_5_metrics #focus on test_score column, which is the accuracy. mean accuracy is 91%, so the true average is likely somehere before 88 and 94%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation scores are in the `test_score` column. To summarize the classifier’s performance:\n",
    "\n",
    "- **Mean (mean)**: Represents the estimated accuracy.\n",
    "- **Standard Error (sem)**: Indicates the uncertainty around this estimate.\n",
    "\n",
    "For example, if the mean accuracy is 0.863 and the standard error is 0.019, the true average accuracy is likely between 84.4% and 88.2%, though it could be outside this range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, now what?\n",
    "\n",
    "To recap, the goal here is to see how accurate our model can be and figure out the best way to make it better. In this case, we still have one parameter we can tweak: the number of neighbors, $K$.\n",
    "\n",
    "To find the best value for $k$ using cross-validation, we can use `GridSearchCV` from Scikit-learn. It automates the process of trying out different values for $k$ and helps us find the one that gives the best accuracy.\n",
    "\n",
    "`GridSearchCV` will test various values for $k$ and select the one that yields the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">***Aside***: Number of Folds vs. Number of Neighbors (k)\n",
    ">\n",
    ">It’s important not to confuse the **number of folds** in cross-validation with the number of neighbors (k) in KNN.\n",
    ">\n",
    ">- **Number of Folds (Cross-Validation)**: Refers to how many parts we split the training data into for evaluation. For example, 5-fold cross-validation trains the model on 4 parts and tests it on the 5th, repeating the process. More folds give a better estimate of model performance but don’t affect the model’s behavior itself.\n",
    ">\n",
    ">- **Number of Neighbors (k in KNN)**: Refers to how many neighbors the model considers when making predictions. Smaller `k` values can lead to overfitting, while larger `k` values smooth predictions. Adjusting `k` directly improves model accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `GridSearchCV` object:\n",
    "\n",
    "-  **Create the GridSearchCV object** by passing:\n",
    "   - `cancer_tune_pipe` as the `estimator`.\n",
    "   - `parameter_grid` as the `param_grid`.\n",
    "   - `cv=10` for 10-fold cross-validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The `range` function in Python generates sequences of numbers. \n",
    "\n",
    "`range(start, stop, step)` creates a sequence from `start` to `stop-1`, incrementing by `step`. For example, `range(1, 100, 5)` produces 1, 6, 11, ..., 96.\n",
    "`range(start, stop)` generates numbers from `start` to `stop-1`. For example, `range(1, 4)` produces 1, 2, 3.\n",
    "`range(stop)` starts from 0 and goes up to `stop-1`. For example, `range(4)` produces 0, 1, 2, 3.\n",
    "\"\"\"\n",
    "\n",
    "parameter_grid = {\n",
    "    \"n_neighbors\": range(1, 100, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_tune_grid = GridSearchCV(\n",
    "    estimator=knn, #specifying machine learning model that we want to tune\n",
    "    param_grid=parameter_grid, #values of parameters that we want to test\n",
    "    cv=10 #10 fold cross validation (splitting our data into ten parts and testing one at a time and comparing with the rest)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.875692</td>\n",
       "      <td>0.038684</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.908638</td>\n",
       "      <td>0.043373</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904042</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920487</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.008055</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>21</td>\n",
       "      <td>{'n_neighbors': 21}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913400</td>\n",
       "      <td>0.046495</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>26</td>\n",
       "      <td>{'n_neighbors': 26}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913400</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>31</td>\n",
       "      <td>{'n_neighbors': 31}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913400</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>36</td>\n",
       "      <td>{'n_neighbors': 36}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.911074</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>41</td>\n",
       "      <td>{'n_neighbors': 41}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.911074</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>46</td>\n",
       "      <td>{'n_neighbors': 46}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.915781</td>\n",
       "      <td>0.045368</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>51</td>\n",
       "      <td>{'n_neighbors': 51}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913455</td>\n",
       "      <td>0.046345</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>56</td>\n",
       "      <td>{'n_neighbors': 56}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>61</td>\n",
       "      <td>{'n_neighbors': 61}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.918106</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>66</td>\n",
       "      <td>{'n_neighbors': 66}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>71</td>\n",
       "      <td>{'n_neighbors': 71}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>76</td>\n",
       "      <td>{'n_neighbors': 76}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.006417</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>81</td>\n",
       "      <td>{'n_neighbors': 81}</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>86</td>\n",
       "      <td>{'n_neighbors': 86}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.915725</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>91</td>\n",
       "      <td>{'n_neighbors': 91}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913344</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>96</td>\n",
       "      <td>{'n_neighbors': 96}</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.913344</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.004939      0.002448         0.009196        0.005253   \n",
       "1        0.003290      0.000942         0.006444        0.001375   \n",
       "2        0.003278      0.000957         0.006330        0.001033   \n",
       "3        0.003011      0.000735         0.007550        0.001865   \n",
       "4        0.003701      0.001015         0.008055        0.001965   \n",
       "5        0.003268      0.000947         0.007525        0.000941   \n",
       "6        0.002968      0.000842         0.006981        0.001369   \n",
       "7        0.003225      0.000887         0.006120        0.001374   \n",
       "8        0.003321      0.000816         0.006090        0.001027   \n",
       "9        0.002984      0.001044         0.006848        0.001201   \n",
       "10       0.002854      0.000602         0.006486        0.001423   \n",
       "11       0.003035      0.000692         0.006061        0.000693   \n",
       "12       0.002873      0.000775         0.005808        0.000734   \n",
       "13       0.002593      0.000371         0.006253        0.000731   \n",
       "14       0.003604      0.000708         0.005988        0.000976   \n",
       "15       0.003375      0.000801         0.006227        0.000813   \n",
       "16       0.003191      0.000544         0.006417        0.000640   \n",
       "17       0.003117      0.000702         0.006080        0.000649   \n",
       "18       0.003225      0.000762         0.006216        0.000952   \n",
       "19       0.003097      0.000751         0.006254        0.000747   \n",
       "\n",
       "    param_n_neighbors               params  split0_test_score  \\\n",
       "0                   1   {'n_neighbors': 1}           0.953488   \n",
       "1                   6   {'n_neighbors': 6}           0.930233   \n",
       "2                  11  {'n_neighbors': 11}           0.906977   \n",
       "3                  16  {'n_neighbors': 16}           0.906977   \n",
       "4                  21  {'n_neighbors': 21}           0.906977   \n",
       "5                  26  {'n_neighbors': 26}           0.906977   \n",
       "6                  31  {'n_neighbors': 31}           0.906977   \n",
       "7                  36  {'n_neighbors': 36}           0.906977   \n",
       "8                  41  {'n_neighbors': 41}           0.906977   \n",
       "9                  46  {'n_neighbors': 46}           0.906977   \n",
       "10                 51  {'n_neighbors': 51}           0.906977   \n",
       "11                 56  {'n_neighbors': 56}           0.906977   \n",
       "12                 61  {'n_neighbors': 61}           0.906977   \n",
       "13                 66  {'n_neighbors': 66}           0.930233   \n",
       "14                 71  {'n_neighbors': 71}           0.930233   \n",
       "15                 76  {'n_neighbors': 76}           0.930233   \n",
       "16                 81  {'n_neighbors': 81}           0.930233   \n",
       "17                 86  {'n_neighbors': 86}           0.906977   \n",
       "18                 91  {'n_neighbors': 91}           0.906977   \n",
       "19                 96  {'n_neighbors': 96}           0.906977   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.837209           0.906977           0.860465   \n",
       "1            0.953488           0.906977           0.837209   \n",
       "2            0.930233           0.906977           0.837209   \n",
       "3            0.953488           0.930233           0.837209   \n",
       "4            0.953488           0.930233           0.837209   \n",
       "5            0.953488           0.930233           0.837209   \n",
       "6            0.953488           0.930233           0.837209   \n",
       "7            0.953488           0.930233           0.837209   \n",
       "8            0.953488           0.930233           0.837209   \n",
       "9            0.953488           0.930233           0.837209   \n",
       "10           0.953488           0.930233           0.837209   \n",
       "11           0.976744           0.930233           0.860465   \n",
       "12           0.953488           0.930233           0.860465   \n",
       "13           0.953488           0.930233           0.860465   \n",
       "14           0.953488           0.930233           0.860465   \n",
       "15           0.976744           0.930233           0.860465   \n",
       "16           0.976744           0.930233           0.860465   \n",
       "17           0.976744           0.930233           0.860465   \n",
       "18           0.976744           0.930233           0.860465   \n",
       "19           0.976744           0.930233           0.860465   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.813953           0.837209           0.880952   \n",
       "1            0.837209           0.906977           0.928571   \n",
       "2            0.837209           0.883721           0.952381   \n",
       "3            0.837209           0.930233           0.952381   \n",
       "4            0.837209           0.906977           0.952381   \n",
       "5            0.837209           0.906977           0.952381   \n",
       "6            0.837209           0.906977           0.952381   \n",
       "7            0.837209           0.883721           0.928571   \n",
       "8            0.837209           0.883721           0.952381   \n",
       "9            0.837209           0.906977           0.952381   \n",
       "10           0.837209           0.883721           0.952381   \n",
       "11           0.837209           0.906977           0.952381   \n",
       "12           0.837209           0.906977           0.952381   \n",
       "13           0.837209           0.906977           0.952381   \n",
       "14           0.837209           0.906977           0.952381   \n",
       "15           0.813953           0.906977           0.952381   \n",
       "16           0.813953           0.906977           0.952381   \n",
       "17           0.813953           0.906977           0.928571   \n",
       "18           0.813953           0.906977           0.904762   \n",
       "19           0.813953           0.906977           0.904762   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.904762           0.880952           0.880952         0.875692   \n",
       "1            0.928571           0.880952           0.976190         0.908638   \n",
       "2            0.904762           0.928571           0.952381         0.904042   \n",
       "3            0.952381           0.928571           0.976190         0.920487   \n",
       "4            0.952381           0.880952           0.976190         0.913400   \n",
       "5            0.928571           0.904762           0.976190         0.913400   \n",
       "6            0.928571           0.904762           0.976190         0.913400   \n",
       "7            0.952381           0.904762           0.976190         0.911074   \n",
       "8            0.928571           0.904762           0.976190         0.911074   \n",
       "9            0.952381           0.904762           0.976190         0.915781   \n",
       "10           0.952381           0.904762           0.976190         0.913455   \n",
       "11           0.952381           0.904762           0.976190         0.920432   \n",
       "12           0.952381           0.904762           0.976190         0.918106   \n",
       "13           0.952381           0.904762           0.976190         0.920432   \n",
       "14           0.952381           0.904762           0.976190         0.920432   \n",
       "15           0.952381           0.904762           0.976190         0.920432   \n",
       "16           0.952381           0.904762           0.976190         0.920432   \n",
       "17           0.952381           0.904762           0.976190         0.915725   \n",
       "18           0.952381           0.904762           0.976190         0.913344   \n",
       "19           0.952381           0.904762           0.976190         0.913344   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.038684               20  \n",
       "1         0.043373               18  \n",
       "2         0.039147               19  \n",
       "3         0.045315                1  \n",
       "4         0.046495               11  \n",
       "5         0.043989               11  \n",
       "6         0.043989               11  \n",
       "7         0.044873               16  \n",
       "8         0.044873               16  \n",
       "9         0.045368                8  \n",
       "10        0.046345               10  \n",
       "11        0.044212                2  \n",
       "12        0.041731                7  \n",
       "13        0.041694                2  \n",
       "14        0.041694                2  \n",
       "15        0.048861                2  \n",
       "16        0.048861                2  \n",
       "17        0.047731                9  \n",
       "18        0.047625               14  \n",
       "19        0.047625               14  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit it to the training data and provide the X (perimeter mean) and Y (concavity mean)\n",
    "\n",
    "cancer_tune_grid.fit(\n",
    "    cancer_train[[\"perimeter_mean\", \"concavity_mean\"]],\n",
    "    cancer_train[\"diagnosis\"]\n",
    ")\n",
    "\n",
    "accuracies_grid = pd.DataFrame(cancer_tune_grid.cv_results_)\n",
    "accuracies_grid\n",
    "\n",
    "#now plot mean test score against parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `GridSearchCV` results, focus on:\n",
    "\n",
    "- **Number of neighbors** (`param_n_neighbors`)\n",
    "- **Cross-validation accuracy estimate** (`mean_test_score`)\n",
    "- **Standard error of the accuracy estimate**\n",
    "\n",
    "GridSearchCV does not directly provide the standard error, but you can compute it using the standard deviation (`std_test_score`) with the formula:\n",
    "\n",
    "$$\n",
    " \\text{Standard Error} = \\frac{\\text{Standard Deviation}}{\\sqrt{\\text{Number of Folds}}} \n",
    " $$\n",
    "\n",
    "This formula allows you to estimate the uncertainty around the accuracy estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies_grid[\"sem_test_score\"] = accuracies_grid[\"std_test_score\"] / 10**(1/2)\n",
    "# accuracies_grid = (\n",
    "#     accuracies_grid[[\n",
    "#         \"param_n_neighbors\",\n",
    "#         \"mean_test_score\",\n",
    "#         \"sem_test_score\"\n",
    "#     ]]\n",
    "#     .rename(columns={\"n_neighbors\": \"param_n_neighbors\"})\n",
    "# )\n",
    "# accuracies_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide which number of neighbors is best by plotting the accuracy versus $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot mean test scores with error bars\n",
    "plt.plot(accuracies_grid['param_n_neighbors'], accuracies_grid['mean_test_score'], '-o', color='blue')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy estimate')\n",
    "plt.title('K-Nearest Neighbors Performance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **also** obtain the number of neighbours with the highest accuracy programmatically by accessing the `best_params_ attribute` of the fit GridSearchCV object. \n",
    "\n",
    "*Note*  it is still useful to visualize the results as we did above since this provides additional information on how the model performance varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 16}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_tune_grid.best_params_\n",
    "\n",
    "# that's the value of k that gives you the best mean accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing 16 neighbors gives the highest cross-validation accuracy estimate at 92%. \n",
    "\n",
    "Remember, these accuracy estimates are approximations. Even though 16 neighbors shows the highest accuracy here, it doesn't guarantee the classifier is truly better with this setting. When selecting parameters, aim for values where:\n",
    "\n",
    "- Accuracy is **roughly** optimal, suggesting the model will perform well.\n",
    "- Nearby values (e.g., slightly higher or lower) don't significantly decrease accuracy, ensuring reliability.\n",
    "- Training costs are manageable (e.g., avoid excessively large parameters that make predictions costly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting\n",
    "\n",
    "As you've seen in the above graph, something unusual happens as the number of neighbors ($k$) increases. The cross-validation accuracy might start to drop when $k$ gets too large. This is because the model becomes too general and starts to \"underfit\" the data. By testing a wider range of $k$ values with `GridSearchCV`, you can see how accuracy changes from small values of $k$ up to nearly the total number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "large_param_grid = {\n",
    "    \"n_neighbors\": range(1, 385, 10),\n",
    "}\n",
    "\n",
    "large_cancer_tune_grid = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=large_param_grid,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "large_cancer_tune_grid.fit(\n",
    "    cancer_train[[\"perimeter_mean\", \"concavity_mean\"]],\n",
    "    cancer_train[\"diagnosis\"]\n",
    ")\n",
    "\n",
    "large_accuracies_grid = pd.DataFrame(large_cancer_tune_grid.cv_results_)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot mean test scores with error bars\n",
    "plt.plot(large_accuracies_grid['param_n_neighbors'], large_accuracies_grid['mean_test_score'], '-o', color='blue')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy estimate')\n",
    "plt.title('K-Nearest Neighbors Performance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of neighbors $k$ increases, the classifier starts to average predictions over more distant points, smoothing the decision boundary and potentially leading to **underfitting**. This means the model becomes too simplistic and less sensitive to individual training examples, which might result in poor performance if the model doesn't capture the complexity of the data.\n",
    "\n",
    "Conversely, with a very small $k$, each data point has a stronger influence, making the decision boundary more jagged and sensitive to noise in the training data. This can lead to **overfitting**, where the model becomes too tailored to the training set and performs poorly on new, unseen data. In the extreme case where  $k$ is 1, the model simply matches new observations to their nearest training example, which can cause significant variability in predictions based on the training data used.\n",
    "\n",
    "📼 A video to better visualize underfitting and overfitting:\n",
    "\n",
    "[![](./images/Underfitting&Overfitting.png)](https://www.youtube.com/watch?v=o3DztvnfAJg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Split the Data**: Use `train_test_split` to divide the data into training and test sets. Set `stratify` to the class label column to maintain class distribution. Set the test set aside.\n",
    "\n",
    "2. **Define the Parameter Grid**: Specify the range of $k$ values to tune.\n",
    "\n",
    "3. **Perform Grid Search**: Use `GridSearchCV` with a parameter grid to estimate accuracy for different $k$ values.\n",
    "\n",
    "4. **Execute Grid Search**: Fit the `GridSearchCV` instance on the training data to find the best $k$.\n",
    "\n",
    "5. **Select Optimal $k$**: Choose the $k$ value with high accuracy and stable performance across nearby values.\n",
    "\n",
    "6. **Retrain the Model**: Create a new model with the best $k$ and fit it to the training data.\n",
    "\n",
    "7. **Evaluate the Model**: Assess the model's accuracy on the test set using the `score` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we worked through several steps to classify tumors as either benign or malignant using the Wisconsin Diagnostic Breast Cancer dataset and evaluate their performance. Here's a summary of what we covered:\n",
    "\n",
    "1. **K-Nearest Neighbors Algorithm (KNN):** We implemented the KNN algorithm and evaluated its performance on a test dataset.\n",
    "\n",
    "2. **Cross-Validation:** We used cross-validation to determine the optimal \n",
    "$k$ value for our classifier.\n",
    "\n",
    "3. **Underfitting/Overfitting**: We explored how varying $k$ can lead to underfitting or overfitting, discussing the implications of choosing a large or small $k$.\n",
    "\n",
    "We hope this notebook has provided a practical understanding of data classification, model evaluation, and the application of machine learning algorithms like KNN. Feel free to experiment further with the dataset or the code to enhance your learning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
